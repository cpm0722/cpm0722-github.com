<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.21.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[NLP 논문 리뷰] Sequence To Sequence Learning With Neural Networks (Seq2Seq) | Hansu Kim’s Dev Blog</title>
<meta name="description" content="Paper Info">


  <meta name="author" content="Hansu Kim">
  
  <meta property="article:author" content="Hansu Kim">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="Hansu Kim's Dev Blog">
<meta property="og:title" content="[NLP 논문 리뷰] Sequence To Sequence Learning With Neural Networks (Seq2Seq)">
<meta property="og:url" content="http://0.0.0.0:4000/machine%20learning/paper%20review/Sequence-to-Sequence-Learning-with-Neural-Networks/">


  <meta property="og:description" content="Paper Info">







  <meta property="article:published_time" content="2020-05-09T19:00:00-05:00">



  <meta property="article:modified_time" content="2020-05-09T19:00:00-05:00">



  

  


<link rel="canonical" href="http://0.0.0.0:4000/machine%20learning/paper%20review/Sequence-to-Sequence-Learning-with-Neural-Networks/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Hansu Kim",
      "url": "http://0.0.0.0:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Hansu Kim's Dev Blog Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->





    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Hansu Kim's Dev Blog
          <span class="site-subtitle">기술 블로그</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/machine-learning/">Machine Learning</a>
            </li><li class="masthead__menu-item">
              <a href="/operating-system/">Operating System</a>
            </li><li class="masthead__menu-item">
              <a href="/system-programming/">System Programming</a>
            </li><li class="masthead__menu-item">
              <a href="/about-me/">About Me</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">토글 메뉴</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/profile.jpg" alt="Hansu Kim" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Hansu Kim</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>ML, NLP를 주로 공부하는 학부생입니다.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">팔로우</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Republic of Korea</span>
        </li>
      

      
        
          
            <li><a href="mailto:cpm0722@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://www.facebook.com/profile.php?id=100003380546271" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-facebook-square" aria-hidden="true"></i><span class="label">Facebook</span></a></li>
          
        
          
            <li><a href="https://github.com/cpm0722" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:cpm0722@gmail.com">
            <meta itemprop="email" content="cpm0722@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[NLP 논문 리뷰] Sequence To Sequence Learning With Neural Networks (Seq2Seq)">
    <meta itemprop="description" content="Paper Info">
    <meta itemprop="datePublished" content="2020-05-09T19:00:00-05:00">
    <meta itemprop="dateModified" content="2020-05-09T19:00:00-05:00">

		<script type="text/javascript" async
		src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
		</script>

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">[NLP 논문 리뷰] Sequence To Sequence Learning With Neural Networks (Seq2Seq)
</h1>
          


        </header>
      

      <section class="page__content" itemprop="text">
        
        <h2 id="paper-info">Paper Info</h2>

<p><a href="https://arxiv.org/abs/1409.3215">Archive Link</a></p>

<p><a href="https://arxiv.org/pdf/1409.3215.pdf">Paper Link</a></p>

<p>Submit Date: Sep 10, 2014</p>

<hr />

<h1 id="introduction">Introduction</h1>

<p>DNN (Deep Neural Network)는 음성 인식, 사물 인식 등에서 꾸준한 성과를 내어왔다. 하지만 input size가 fixed된다는 한계점이 존재하기 때문에 sequencial problem을 제대로 해결할 수 없다는 한계점이 존재했다. 본 논문에서는 2개의 LSTM (Long Short Term Memory)을 각각 Encoder, Decoder로 사용해 sequencial problem을 해결하고자 했다. 이를 통해 많은 성능 향상을 이루어냈으며, 특히나 long sentence에서 더 큰 상승 폭을 보였다. 이에 더해 단어를 역순으로 배치하는 방식으로도 성능을 향상시켰다.</p>

<h1 id="the-model">The model</h1>

<p><img src="/assets/images/2020-05-10-Sequence-to-Sequence-Learning-with-Neural-Networks/01.jpg" alt="01.jpg" /></p>

\[h_t = sigmoid\left(W^{hx}x_t + W^{hh}h_{t-1}\right)\\y_t = W^{yh}h_t\]

\[p\left(y_1,\cdots,y_{T'}|x_1,\cdots,x_T\right)=\prod_{t=1}^{T'}p\left(y_t|v,y_1,\cdots,y_{t-1}\right)\]

<p>RNN은 기본적으로 sequencial problem에 매우 적절한 model이다. 하지만 input size와 output size가 다른 경우에 대해서는 좋은 성능을 보일 수 없었다. 본 논문에서 제시하는 model은 Encoder LSTM에서 하나의 context vector를 생성한 뒤 Decoder LSTM에서 context vector를 이용해 output sentence를 생성하는 방식으로 RNN의 한계점을 극복하고자 했다. input과 output sentence 간의 mapping을 하는 것이 아닌, input sentence를 통해 encoder에서 context vector를 생성하고, 이를 활용해 decoder에서 output sentence를 만들어내는 것이다. Encoder LSTM의 output인 context vector는 Encoder의 마지막 layer에서 나온 output이다. 이를 Decoder LSTM의 첫번째 layer의 input으로 넣게 된다. 여기서 주목할만한 점은 input sentence에서의 word order를 reverse해 사용했다는 것이다. 또한 <EOS> (End of Sentence) token을 각 sentence의 끝에 추가해 variable length sentence를 다뤘다.</EOS></p>

<h2 id="experiments">Experiments</h2>

<p>WMT’14의 English to French dataset으로 실험을 진행했다. source / target language 각각에 fixed size vocabulary를 사용했다 (source: 160,000 / target: 80,000). OOV는 “UNK” token으로 대체된다. long sequence에서는 source sentence를 reverse시킨 경우가 특히나 성능이 더 좋았다. 구체적인 수치로 BLEU score가 25.9에서 30.6으로 증가했다.</p>

<ul>
  <li>원래의 순서대로 나열된 단어의 경우 source와 target에서의 연결되는 단어쌍(pair of word) 사이의 거리가 모두 동일하다. 하지만 reverse시킬 경우에는 sentence에서 앞에 위치한 단어일수록 단어쌍 사이의 거리가 짧아지게 된다. 이는 결국 sentence에서 뒤에 위치한 단어들에 대해서는 오히려 reverse하지 않았을 때보다 단어쌍 사이의 거리가 멀어지는 결과를 낳는다. 생각해보면 결국 reverse한 뒤나, 하지 않았을 때에나 단어쌍 사이의 거리 mean값은 동일하다. 그런데 왜 reverse시 더 좋은 성능이 나오는 것인지 의문일 수 있는데, sequencial problem의 개념으로 다시 돌아와 생각해보면 어느정도 이유를 추론 가능하다. sequencial problem에서는 앞쪽에 위치한 data가 뒤의 모든 data에 영향을 주기 때문에 앞에 위치한 data일 수록 중요도가 더 높다고 할 수 있다. 따라서 reverse를 통해 source sentence에서 앞쪽에 위치한 data(word)들의 target sentence에서의 연관 word와의 거리를 줄이는 것은 더 중요도 높은 data에 대해 더 좋은 성능을 보장하게 되는 효과를 낳는다.</li>
</ul>

<p>dataset의 대부분은 short length sentence이기에 mini batch 사용 시 각 batch 마다 아주 적은 수의 long length sentence가 포함되는 문제가 존재했다. 따라서 각 batch마다 대략적으로 비슷한 length를 가진 sentence가 포함되도록 normalization을 수행한 뒤 실험을 진행했다.</p>

<p><img src="/assets/images/2020-05-10-Sequence-to-Sequence-Learning-with-Neural-Networks/02.jpg" alt="02.jpg" /></p>

<p><img src="/assets/images/2020-05-10-Sequence-to-Sequence-Learning-with-Neural-Networks/03.jpg" alt="03.jpg" /></p>

<p>SOTA(State of the Art)에 비해 0.5 낮은 BLEU Score를 달성했다. OOV가 여전히 존재함에도 SOTA와 동등한 성능을 달성했다는 것은 충분히 의미가 있다.</p>

<p>위에서 언급했듯이 long Sentence에서도 매우 좋은 성능을 보였다.</p>

<p><img src="/assets/images/2020-05-10-Sequence-to-Sequence-Learning-with-Neural-Networks/04.jpg" alt="04.jpg" /></p>

<p><img src="/assets/images/2020-05-10-Sequence-to-Sequence-Learning-with-Neural-Networks/05.jpg" alt="05.jpg" /></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#nlp" class="page__taxonomy-item" rel="tag">NLP</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/#machine-learning" class="page__taxonomy-item" rel="tag">Machine Learning</a><span class="sep">, </span>
    
      
      
      <a href="/categories/#paper-review" class="page__taxonomy-item" rel="tag">Paper Review</a>
    
    </span>
  </p>


        
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time datetime="2020-05-10">May 10, 2020</time></p>


      </footer>

      <!--<section class="page__share">
  
    <h4 class="page__share-title">공유하기</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%5BNLP+%EB%85%BC%EB%AC%B8+%EB%A6%AC%EB%B7%B0%5D+Sequence+To+Sequence+Learning+With+Neural+Networks+%28Seq2Seq%29%20http%3A%2F%2F0.0.0.0%3A4000%2Fmachine%2520learning%2Fpaper%2520review%2FSequence-to-Sequence-Learning-with-Neural-Networks%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2F0.0.0.0%3A4000%2Fmachine%2520learning%2Fpaper%2520review%2FSequence-to-Sequence-Learning-with-Neural-Networks%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2F0.0.0.0%3A4000%2Fmachine%2520learning%2Fpaper%2520review%2FSequence-to-Sequence-Learning-with-Neural-Networks%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>
-->

      
<nav class="pagination">
	
		<a href="/machine%20learning/paper%20review/Neural-Machine-Translation-of-Rare-Words-with-Subword-Units/" class="pagination--pager" title="[NLP 논문 리뷰] Neural Machine Translation of Rare Words with Subword Units (BPE)
">이전</a>
	
	
		<a href="/system%20programming/unix/Directory-Manager/" class="pagination--pager" title="[System programming] 디렉터리 관리 프로그램 구현
">다음</a>
	
</nav>


    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">최근 포스트</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/machine%20learning/paper%20review/Deep-contextualized-word-representations/" rel="permalink">[NLP 논문 리뷰] Deep Contextualized Word Representations (ELMo)
</a>
      
    </h2>
    


    <p class="archive__item-excerpt" itemprop="description">Paper Info
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/machine%20learning/paper%20review/Efficient-Estimation-of-Word-Representations-in-Vector-Space/" rel="permalink">[NLP 논문 리뷰] Efficient Estimation Of Word Representations In Vector Space (Word2Vec)
</a>
      
    </h2>
    


    <p class="archive__item-excerpt" itemprop="description">Paper Info
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/machine%20learning/paper%20review/KR-BERT-A-Small-Scale-Korean-Specific-Language-Model/" rel="permalink">[NLP 논문 리뷰] KR-BERT: A Small Scale Korean Specific Language Model
</a>
      
    </h2>
    


    <p class="archive__item-excerpt" itemprop="description">Paper Info
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/machine%20learning/paper%20review/An-Empirical-Study-of-Tokenization-Strategies-for-Various-Korean-NLP-Tasks/" rel="permalink">[NLP 논문 리뷰] An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks
</a>
      
    </h2>
    


    <p class="archive__item-excerpt" itemprop="description">Paper Info
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우</strong></li>
    

    
      
        
          <li><a href="mailto:cpm0722@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
        
      
        
          <li><a href="https://www.facebook.com/profile.php?id=100003380546271" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-facebook-square" aria-hidden="true"></i> Facebook</a></li>
        
      
        
          <li><a href="https://github.com/cpm0722" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> RSS</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Hansu Kim. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>







    
  <script>
    var disqus_config = function () {
      this.page.url = "http://0.0.0.0:4000/machine%20learning/paper%20review/Sequence-to-Sequence-Learning-with-Neural-Networks/";  /* Replace PAGE_URL with your page's canonical URL variable */
      this.page.identifier = "/machine%20learning/paper%20review/Sequence-to-Sequence-Learning-with-Neural-Networks"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */
    };
    (function() { /* DON'T EDIT BELOW THIS LINE */
      var d = document, s = d.createElement('script');
      s.src = 'https://cpm0722.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  





  </body>
</html>
