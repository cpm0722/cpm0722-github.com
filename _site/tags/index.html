<!DOCTYPE html> <!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]--> <!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]--> <!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]--> <!--[if gt IE 8]><!--> <html class="no-js"><!--<![endif]--> <head> <meta charset="UTF-8"> <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> <meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"> <title>Tag Archive &#8211; Hansu Kim</title> <meta name="description" content="An archive of posts sorted by tag."> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="http://192.168.50.41:4000/assets/images/profile.jpg"> <meta name="twitter:title" content="Tag Archive"> <!-- Open Graph --> <meta property="og:locale" content="ko-KR"> <meta property="og:type" content="article"> <meta property="og:title" content="Tag Archive"> <meta property="og:url" content="http://192.168.50.41:4000/tags/"> <meta property="og:site_name" content="Hansu Kim"> <meta property="og:image" content="http://192.168.50.41:4000/assets/images/profile.jpg"> <link rel="canonical" href="http://192.168.50.41:4000/tags/"> <link href="http://192.168.50.41:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Hansu Kim Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="http://192.168.50.41:4000/assets/css/main.css"> <!-- JS --> <script src="http://192.168.50.41:4000/assets/js/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" href="http://192.168.50.41:4000/assets/img/favicons/apple-icon-precomposed.png"> <link rel="apple-touch-icon" sizes="72x72" href="http://192.168.50.41:4000/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="http://192.168.50.41:4000/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="http://192.168.50.41:4000/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="http://192.168.50.41:4000/favicon.png" /> <link rel="shortcut icon" href="http://192.168.50.41:4000/favicon.ico" /> <!-- Background Image --> <style type="text/css">body {background-image:url(http://192.168.50.41:4000/assets/images/placeholder-big.jpg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> </head> <body> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="http://192.168.50.41:4000/">Home</a></li> <li> <a href="#">About</a> <ul class="dl-submenu"> <li> <img src="http://192.168.50.41:4000/assets/images/profile.jpg" alt="Hansu Kim photo" class="author-photo"> <h4>Hansu Kim</h4> <p>Hansu Kim's Development Blog</p> </li> <li><a href="http://192.168.50.41:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="http://facebook.com/cpm0722" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-facebook-square"></i> Facebook</a> </li> <li> <a href="http://instagram.com/cpm0722" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-instagram"></i> Instagram</a> </li> <li> <a href="http://github.com/cpm0722" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> </ul><!-- /.dl-submenu --> </li> <li><a href="http://192.168.50.41:4000/posts/">Post Archive</a></li> <li><a href="http://192.168.50.41:4000/tags/">Tag Archive</a></li> <!-- <li> <a href="#">Posts</a> <ul class="dl-submenu"> <li><a href="http://192.168.50.41:4000/posts/">All Posts</a></li> <li><a href="http://192.168.50.41:4000/tags/">All Tags</a></li> </ul> </li> --!> <li><a href="http://192.168.50.41:4000/machine-learning/" >Machine Learning</a></li> <li><a href="http://192.168.50.41:4000/operating-system/" >Operating System</a></li> <li><a href="http://192.168.50.41:4000/system-programming/" >System Programming</a></li> </ul><!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title "> <h1>Tag Archive</h1> <a class="btn zoombtn" href="http://192.168.50.41:4000"> <i class="fa fa-chevron-left"></i> </a> </div> <ul class="entry-meta inline-list"> <li><a href="#Korean NLP" class="tag"><span class="term">Korean NLP</span> <span class="count">3</span></a></li> <li><a href="#ML General" class="tag"><span class="term">ML General</span> <span class="count">1</span></a></li> <li><a href="#NLP" class="tag"><span class="term">NLP</span> <span class="count">15</span></a></li> <li><a href="#Operating System" class="tag"><span class="term">Operating System</span> <span class="count">10</span></a></li> <li><a href="#Pytorch" class="tag"><span class="term">Pytorch</span> <span class="count">1</span></a></li> <li><a href="#System Programming" class="tag"><span class="term">System Programming</span> <span class="count">5</span></a></li> </ul> <article> <h2 id="Korean NLP" class="tag-heading">Korean NLP</h2> <ul> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/kr-bert-a-small-scale-korean-specific-language-model" title="[NLP 논문 리뷰] KR-BERT: A Small Scale Korean Specific Language Model">[NLP 논문 리뷰] KR-BERT: A Small Scale Korean Specific Language Model</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/an-empirical-study-of-tokenization-strategies-for-various-korean-nlp-tasks" title="[NLP 논문 리뷰] An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks">[NLP 논문 리뷰] An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/subword-level-word-vector-representation-for-korean" title="[NLP 논문 리뷰] Subword-level Word Vector Representation for Korean">[NLP 논문 리뷰] Subword-level Word Vector Representation for Korean</a></li> </ul> </article><!-- /.hentry --> <article> <h2 id="ML General" class="tag-heading">ML General</h2> <ul> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/distilling-the-knowledge-in-a-neural-network" title="[ML 논문 리뷰] Distilling the Knowledge in a Neural Network">[ML 논문 리뷰] Distilling the Knowledge in a Neural Network</a></li> </ul> </article><!-- /.hentry --> <article> <h2 id="NLP" class="tag-heading">NLP</h2> <ul> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/distilbert-a-distilled-version-of-bert-smaller-faster-cheaper-and-lighter" title="[NLP 논문 리뷰] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter">[NLP 논문 리뷰] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/pytorch-implementation/transformer" title="[NLP 논문 구현] pytorch로 구현하는 Transformer (Attention is All You Need)">[NLP 논문 구현] pytorch로 구현하는 Transformer (Attention is All You Need)</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/deep-contextualized-word-representations" title="[NLP 논문 리뷰] Deep Contextualized Word Representations (ELMo)">[NLP 논문 리뷰] Deep Contextualized Word Representations (ELMo)</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/efficient-estimation-of-word-representations-in-vector-space" title="[NLP 논문 리뷰] Efficient Estimation Of Word Representations In Vector Space (Word2Vec)">[NLP 논문 리뷰] Efficient Estimation Of Word Representations In Vector Space (Word2Vec)</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/kr-bert-a-small-scale-korean-specific-language-model" title="[NLP 논문 리뷰] KR-BERT: A Small Scale Korean Specific Language Model">[NLP 논문 리뷰] KR-BERT: A Small Scale Korean Specific Language Model</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/an-empirical-study-of-tokenization-strategies-for-various-korean-nlp-tasks" title="[NLP 논문 리뷰] An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks">[NLP 논문 리뷰] An Empirical Study of Tokenization Strategies for Various Korean NLP Tasks</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/machine%20learning/paper%20review/2020/10/05/RoBERTa-A-Robustly-Optimized-BERT-Pretraining-Approach.html" title="[NLP 논문 리뷰] RoBERTa: A Robustly Optimized BERT Pretraining Approach">[NLP 논문 리뷰] RoBERTa: A Robustly Optimized BERT Pretraining Approach</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/subword-level-word-vector-representation-for-korean" title="[NLP 논문 리뷰] Subword-level Word Vector Representation for Korean">[NLP 논문 리뷰] Subword-level Word Vector Representation for Korean</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/mass-masked-sequence-to-sequence-pre-training-for-language-generation" title="[NLP 논문 리뷰] MASS: Masked Sequence To Sequence Pre Training For Language Generation">[NLP 논문 리뷰] MASS: Masked Sequence To Sequence Pre Training For Language Generation</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/xlnet-generalized-autoregressive-pretraining-for-language-understanding" title="[NLP 논문 리뷰] Xlnet: Generalized Autoregressive Pretraining for Language Understanding">[NLP 논문 리뷰] Xlnet: Generalized Autoregressive Pretraining for Language Understanding</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding" title="[NLP 논문 리뷰] BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding">[NLP 논문 리뷰] BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/attention-is-all-you-need" title="[NLP 논문 리뷰] Attention Is All You Need (Transformer)">[NLP 논문 리뷰] Attention Is All You Need (Transformer)</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/neural-machine-translation-by-jointly-learning-to-align-and-translate" title="[NLP 논문 리뷰] Neural Machine Translation By Jointly Learning To Align And Translate (Attention Seq2Seq)">[NLP 논문 리뷰] Neural Machine Translation By Jointly Learning To Align And Translate (Attention Seq2Seq)</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/sequence-to-sequence-learning-with-neural-networks" title="[NLP 논문 리뷰] Sequence To Sequence Learning With Neural Networks (Seq2Seq)">[NLP 논문 리뷰] Sequence To Sequence Learning With Neural Networks (Seq2Seq)</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/paper-review/neural-machine-translation-of-rare-words-with-subword-units" title="[NLP 논문 리뷰] Neural Machine Translation of Rare Words with Subword Units (BPE)">[NLP 논문 리뷰] Neural Machine Translation of Rare Words with Subword Units (BPE)</a></li> </ul> </article><!-- /.hentry --> <article> <h2 id="Operating System" class="tag-heading">Operating System</h2> <ul> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/disk" title="[운영체제] Disk">[운영체제] Disk</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/file-system" title="[운영체제] File System">[운영체제] File System</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/semaphore" title="[운영체제] Semaphore">[운영체제] Semaphore</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/concurrency" title="[운영체제] Concurrency">[운영체제] Concurrency</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/paging-mechanism" title="[운영체제] Paging Mechanism">[운영체제] Paging Mechanism</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/address-and-memory" title="[운영체제] Address and Memory">[운영체제] Address and Memory</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/scheduling-mlfq-multi-level-feedback-queue" title="[운영체제] Scheduling: MLFQ(Multi Level Feedback Queue)">[운영체제] Scheduling: MLFQ(Multi Level Feedback Queue)</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/scheduling" title="[운영체제] Scheduling">[운영체제] Scheduling</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/process-abstraction" title="[운영체제] Process Abstraction">[운영체제] Process Abstraction</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/operating-system/introduction-to-operating-systems" title="[운영체제] Introduction to Operating Systems">[운영체제] Introduction to Operating Systems</a></li> </ul> </article><!-- /.hentry --> <article> <h2 id="Pytorch" class="tag-heading">Pytorch</h2> <ul> <li class="entry-title"><a href="http://192.168.50.41:4000/pytorch-implementation/transformer" title="[NLP 논문 구현] pytorch로 구현하는 Transformer (Attention is All You Need)">[NLP 논문 구현] pytorch로 구현하는 Transformer (Attention is All You Need)</a></li> </ul> </article><!-- /.hentry --> <article> <h2 id="System Programming" class="tag-heading">System Programming</h2> <ul> <li class="entry-title"><a href="http://192.168.50.41:4000/system-programming/top-command" title="[System Programming] top 명령어 구현">[System Programming] top 명령어 구현</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/system-programming/ps-command" title="[System Programming] ps 명령어 구현">[System Programming] ps 명령어 구현</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/system-programming/shell" title="[System Programming] Shell 구현">[System Programming] Shell 구현</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/system-programming/sync-manager" title="[System Programming] 동기화 프로그램 구현">[System Programming] 동기화 프로그램 구현</a></li> <li class="entry-title"><a href="http://192.168.50.41:4000/system-programming/directory-manager" title="[System programming] 디렉터리 관리 프로그램 구현">[System programming] 디렉터리 관리 프로그램 구현</a></li> </ul> </article><!-- /.hentry --> </div> </div> </header> <!-- JS --> <script src="http://192.168.50.41:4000/assets/js/jquery-1.12.0.min.js"></script> <script src="http://192.168.50.41:4000/assets/js/jquery.dlmenu.min.js"></script> <script src="http://192.168.50.41:4000/assets/js/jquery.goup.min.js"></script> <script src="http://192.168.50.41:4000/assets/js/jquery.magnific-popup.min.js"></script> <script src="http://192.168.50.41:4000/assets/js/jquery.fitvid.min.js"></script> <script src="http://192.168.50.41:4000/assets/js/scripts.js"></script> <!-- MathJax --> <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </body> </html>
